# TOTAL_SCOPE
Сделать vision-слой, который в реальном времени понимает, что на экране, и отдаёт JSON со структурой UI:
- Захват экрана (30 fps)
- Очередь/буфер кадров
- Preprocess (в т.ч. опциональный downscale)
- Детекция UI-элементов (bbox + class)
- Трекинг (stable_id между кадрами)
- OCR текста (по bbox/по событию + кеш)
- Сборка структуры (плоский список и/или UI tree)
- JSON-схема и stream API
- Метрики (fps/latency) + отладка

# 1st_STEP_SCOPE
Сделать модуль "Screen Capture Pipeline" (без ML):
- Screen Capture: получать кадры экрана в реальном времени
- Frame Buffer: хранить последние N кадров, не блокировать захват
- Preprocess: делать вторую версию кадра для ML (например уменьшенную), но сохранять оригинал
- Frame Stream API: простой интерфейс "получи последний кадр" и/или "подпишись на поток"
Критерии готовности:
- стабильные ~30 fps захвата
- понятные таймстемпы
- система не падает, если downstream тормозит (кадры пропускаются/перезаписываются в буфере)
